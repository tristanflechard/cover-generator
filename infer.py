from core import run_infer_script
import os

output_path = "outputs"
vocal_path = "split_audios/vocal_La Feve - Comme des enfants.wav"
model_full_path = "logs/model/Ademo"
# Run inference directly with default parameters
run_infer_script(
    pitch=0,
    filter_radius=3,
    index_rate=0.3,
    volume_envelope=1,
    protect=0.33,
    hop_length=128,
    f0_method="rmvpe",
    input_path=vocal_path,
    output_path="test.wav",
    pth_path=os.path.join(model_full_path, "model.pth"),
    index_path=os.path.join(model_full_path, "model.index"),
    split_audio=False,
    f0_autotune=False,
    f0_autotune_strength=1.0,
    clean_audio=False,
    clean_strength=0.7,
    export_format="WAV",
    f0_file=None,
    embedder_model="contentvec",
    embedder_model_custom=None,
    formant_shifting=False,
    formant_qfrency=1.0,
    formant_timbre=1.0,
    post_process=False,
    reverb=False,
    pitch_shift=False,
    limiter=False,
    gain=False,
    distortion=False,
    chorus=False,
    bitcrush=False,
    clipping=False,
    compressor=False,
    delay=False,
    reverb_room_size=0.5,
    reverb_damping=0.5,
    reverb_wet_gain=0.5,
    reverb_dry_gain=0.5,
    reverb_width=0.5,
    reverb_freeze_mode=0.5,
    pitch_shift_semitones=0.0,
    limiter_threshold=-6,
    limiter_release_time=0.01,
    gain_db=0.0,
    distortion_gain=25,
    chorus_rate=1.0,
    chorus_depth=0.25,
    chorus_center_delay=7,
    chorus_feedback=0.0,
    chorus_mix=0.5,
    bitcrush_bit_depth=8,
    clipping_threshold=-6,
    compressor_threshold=0,
    compressor_ratio=1,
    compressor_attack=1.0,
    compressor_release=100,
    delay_seconds=0.5,
    delay_feedback=0.0,
    delay_mix=0.5,
    sid=0,
)
